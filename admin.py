import asyncio
import csv
import json
from datetime import datetime, timedelta
from database import Database
import config

db = Database()

class AdminTools:
    @staticmethod
    async def get_user_stats_csv():
        """–í—ã–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ CSV"""
        async with db.pool.acquire() as conn:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            rows = await conn.fetch("""
                SELECT 
                    u.id,
                    u.telegram_id,
                    u.name,
                    u.interest_area,
                    u.expertise_area,
                    u.created_at,
                    COUNT(DISTINCT l_sent.id) as likes_sent,
                    COUNT(DISTINCT l_received.id) as likes_received,
                    COUNT(DISTINCT s.id) as skips_sent,
                    (SELECT COUNT(*) FROM likes l2 
                     JOIN users u2 ON l2.from_user_id = u2.id 
                     WHERE l2.to_user_id = u.id 
                     AND EXISTS (
                         SELECT 1 FROM likes l3 
                         WHERE l3.from_user_id = u.id 
                         AND l3.to_user_id = l2.from_user_id
                     )) as mutual_likes,
                    CASE 
                        WHEN (SELECT COUNT(*) FROM likes WHERE from_user_id = u.id) > 0 
                        THEN ROUND(
                            ((SELECT COUNT(*) FROM likes WHERE to_user_id = u.id)::numeric /
                            (SELECT COUNT(*) FROM likes WHERE from_user_id = u.id)::numeric)::numeric, 
                            2
                        )
                        ELSE 0.0 
                    END as like_ratio
                FROM users u
                LEFT JOIN likes l_sent ON l_sent.from_user_id = u.id
                LEFT JOIN likes l_received ON l_received.to_user_id = u.id
                LEFT JOIN skips s ON s.from_user_id = u.id
                GROUP BY u.id
                ORDER BY u.created_at DESC
            """)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä–∏
            dict_rows = [dict(row) for row in rows]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
            filename = f"user_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            with open(filename, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=[
                    'id', 'telegram_id', 'name', 'interest_area', 'expertise_area',
                    'created_at', 'likes_sent', 'likes_received', 'skips_sent',
                    'mutual_likes', 'like_ratio'
                ])
                writer.writeheader()
                for row in dict_rows:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º datetime –≤ —Å—Ç—Ä–æ–∫—É
                    row_dict = dict(row)
                    if 'created_at' in row_dict and row_dict['created_at']:
                        row_dict['created_at'] = row_dict['created_at'].isoformat()
                    writer.writerow(row_dict)
            
            return filename, len(dict_rows)

    @staticmethod
    async def get_activity_timeline(days=7):
        """–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –¥–Ω—è–º"""
        async with db.pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT 
                    DATE(created_at) as date,
                    COUNT(CASE WHEN table_name = 'users' THEN 1 END) as new_users,
                    COUNT(CASE WHEN table_name = 'likes' THEN 1 END) as likes,
                    COUNT(CASE WHEN table_name = 'skips' THEN 1 END) as skips
                FROM (
                    SELECT created_at, 'users' as table_name FROM users
                    UNION ALL
                    SELECT created_at, 'likes' as table_name FROM likes
                    UNION ALL
                    SELECT created_at, 'skips' as table_name FROM skips
                ) all_events
                WHERE created_at >= CURRENT_DATE - ($1 || ' days')::interval
                GROUP BY DATE(created_at)
                ORDER BY date
            """, str(days))
            
            return [dict(row) for row in rows]

    @staticmethod
    async def get_top_interests(limit=10):
        """–°–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã"""
        async with db.pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT 
                    interest_area,
                    COUNT(*) as user_count,
                    COALESCE(
                        ROUND(
                            AVG(
                                CASE 
                                    WHEN (SELECT COUNT(*) FROM likes WHERE from_user_id = u.id) > 0 
                                    THEN (SELECT COUNT(*) FROM likes WHERE to_user_id = u.id)::numeric /
                                         (SELECT COUNT(*) FROM likes WHERE from_user_id = u.id)::numeric
                                    ELSE 0.0 
                                END
                            )::numeric,
                            2
                        ),
                        0.0
                    ) as avg_like_ratio
                FROM users u
                WHERE interest_area IS NOT NULL AND interest_area != ''
                GROUP BY interest_area
                ORDER BY user_count DESC
                LIMIT $1
            """, limit)
            
            return [dict(row) for row in rows]

    @staticmethod
    async def get_simple_stats():
        """–ü—Ä–æ—Å—Ç–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π)"""
        async with db.pool.acquire() as conn:
            # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_users = await conn.fetchval("SELECT COUNT(*) FROM users")
            total_likes = await conn.fetchval("SELECT COUNT(*) FROM likes")
            total_skips = await conn.fetchval("SELECT COUNT(*) FROM skips")
            
            # –ù–æ–≤—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
            new_today = await conn.fetchval("""
                SELECT COUNT(*) FROM users 
                WHERE created_at::date = CURRENT_DATE
            """)
            
            # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–µ–≥–æ–¥–Ω—è
            active_today = await conn.fetchval("""
                SELECT COUNT(DISTINCT from_user_id) FROM likes
                WHERE created_at::date = CURRENT_DATE
            """)
            
            # –í–∑–∞–∏–º–Ω—ã–µ –ª–∞–π–∫–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å)
            mutual = await conn.fetchval("""
                SELECT COUNT(*) FROM (
                    SELECT DISTINCT LEAST(l1.from_user_id, l1.to_user_id) as user1,
                                    GREATEST(l1.from_user_id, l1.to_user_id) as user2
                    FROM likes l1
                    JOIN likes l2 ON l1.from_user_id = l2.to_user_id 
                        AND l1.to_user_id = l2.from_user_id
                ) t
            """)
            
            return {
                'total_users': total_users,
                'total_likes': total_likes,
                'total_skips': total_skips,
                'new_today': new_today,
                'active_today': active_today,
                'mutual_likes': mutual
            }

    @staticmethod
    async def export_full_database():
        """–ü–æ–ª–Ω–∞—è –≤—ã–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –¥–ª—è –±—ç–∫–∞–ø–∞"""
        async with db.pool.acquire() as conn:
            # –í—Å–µ —Ç–∞–±–ª–∏—Ü—ã
            tables = ['users', 'likes', 'skips']
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            exported_files = []
            
            for table in tables:
                rows = await conn.fetch(f"SELECT * FROM {table}")
                filename = f"{table}_export_{timestamp}.json"
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ –≤ —Å–ª–æ–≤–∞—Ä–∏
                data = []
                for row in rows:
                    row_dict = {}
                    for key, value in dict(row).items():
                        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º datetime –≤ —Å—Ç—Ä–æ–∫—É
                        if hasattr(value, 'isoformat'):
                            row_dict[key] = value.isoformat()
                        else:
                            row_dict[key] = value
                    data.append(row_dict)
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                
                print(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {table} –≤ {filename}")
                exported_files.append(filename)
            
            return f"–≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω. –§–∞–π–ª—ã: {', '.join(exported_files)}"

# –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
async def test_admin_tools():
    await db.create_pool()
    
    print("üìä –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–¥–º–∏–Ω-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã...")
    
    try:
        # 1. –ü—Ä–æ—Å—Ç–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\nüìà –ü—Ä–æ—Å—Ç–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        stats = await AdminTools.get_simple_stats()
        for key, value in stats.items():
            print(f"   {key}: {value}")
        
        # 2. CSV –≤—ã–≥—Ä—É–∑–∫–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
        print("\nüì§ –¢–µ—Å—Ç–∏—Ä—É–µ–º CSV –≤—ã–≥—Ä—É–∑–∫—É...")
        filename, count = await AdminTools.get_user_stats_csv()
        print(f"‚úÖ –í—ã–≥—Ä—É–∂–µ–Ω–æ {count} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ {filename}")
        
        # 3. –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        print("\nüìä –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∑–∞ 7 –¥–Ω–µ–π:")
        activity = await AdminTools.get_activity_timeline(7)
        print(f"   –í—Å–µ–≥–æ –¥–Ω–µ–π —Å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é: {len(activity)}")
        if activity:
            for day in activity[:3]:  # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 3 –¥–Ω—è
                date_str = day['date'].strftime('%d.%m') if hasattr(day['date'], 'strftime') else str(day['date'])
                print(f"   {date_str}: +{day['new_users']} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, {day['likes']} –ª–∞–π–∫–æ–≤")
        
        # 4. –¢–æ–ø –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤
        print("\nüéØ –¢–æ–ø –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤:")
        top = await AdminTools.get_top_interests(5)
        for i, item in enumerate(top, 1):
            print(f"   {i}. {item['interest_area']}: {item['user_count']} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
        
        print("\nüéâ –í—Å–µ –∞–¥–º–∏–Ω-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")
        
        # –ü–æ–∫–∞–∂–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ CSV
        print(f"\nüìÑ –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏ –∏–∑ {filename}:")
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                for i, line in enumerate(lines[:4]):  # –ó–∞–≥–æ–ª–æ–≤–æ–∫ + 3 —Å—Ç—Ä–æ–∫–∏
                    print(f"   {line.strip()}")
        except:
            pass
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_admin_tools())